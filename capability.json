{
  "name": "ollama-llm",
  "version": "1.0",
  "description": "Local LLM capability powered by Ollama. Provides text generation for prompt-based AI tasks.",
  "provides": ["text-generation"],
  "api": {
    "endpoint": "http://localhost:11434",
    "type": "REST",
    "health_check": "/api/tags"
  },
  "resources": {
    "ram_mb": 6000,
    "cpu_cores": 4,
    "storage_mb": 8000
  },
  "container": {
    "image": "docker.io/ollama/ollama",
    "port": 11434,
    "restart_policy": "unless-stopped"
  },
  "target_platforms": ["Raspberry Pi 5 (16GB)", "Raspberry Pi 4 (8GB)", "AMD64 (24GB+)"],
  "supported_architectures": ["arm64", "amd64"],
  "notes": "This capability contract defines the interface for text-generation services in eZansiEdgeAI. Other capabilities must expose the same 'provides' and resource fields. Supports both ARM64 (Raspberry Pi) and AMD64 (x86-64) architectures."
}
